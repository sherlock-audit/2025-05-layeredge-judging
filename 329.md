Suave Blood Armadillo

Medium

# `MAX_USERS` can be exceeded as the system can generate a `joinId` above the cap, resulting in broken state, an incorrect tier allocation system and a broken invariant

### Summary

The lack of an explicit check to prevent `nextJoinId` from exceeding `MAX_USERS` in `LayerEdgeStaking._stake()` combined with the `FenwickTree.update()` function silently failing for out of bounds `joinIds` will cause broken state for the protocol as any user attempting to stake after `MAX_USERS` `joinIds` have been issued will trigger this vulnerability. This leads to an inflated `stakerCountInTree`, an inconsistent `UserInfo.outOfTree` status for the affected user, and consequently, incorrect tier percentage calculations for all users in the system, breaking an important invariant:

> 1. Tier distribution correctness: Exactly 20% in Tier 1, 30% in Tier 2, and 50% in Tier 3 (with minimum guarantees of at least 1 user per tier when applicable)

Not that this carries any weight according to sherlock guidelines, but the sponsor has confirmed the validity of this issue in our private thread.

Worth nothing that the likelihood for this issue to occur is low as it means `100_000_000` wallets have staked under this condition `amount >= minStakeAmount` **BUT** likelihood has no weight as per sherlock guidelines:

> Note
Likelihood is not considered when identifying the severity and the validity of the report.

An attacker can also accelerate the consumption of `joinIds` to trigger this broken state faster.

### Root Cause

In [`LayerEdgeStaking.sol:674-723`](https://github.com/sherlock-audit/2025-05-layeredge/blob/main/edgen-staking/src/stake/LayerEdgeStaking.sol#L674-L723), when a new user stakes when `MAX_USERS` has been reached through assigning `joinId`'s above `MAX_USERS` and is eligible for the tier system `(!user.isActive && amount >= minStakeAmount)`:

1. A `joinId` is assigned from `nextJoinId++` without checking if nextJoinId is already `> MAX_USERS`.
2. `stakerTree.update(user.joinId, 1)` is called. If `user.joinId` is greater than `stakerTree.size` (which is initialized to `MAX_USERS`), the underlying `FenwickTree.update()` function's loop [`while (index <= self.size)`](https://github.com/sherlock-audit/2025-05-layeredge/blob/main/edgen-staking/src/library/FenwickTree.sol#L12-L14) does not execute, resulting in a silent failure to add the user to the tree.
3. Despite this silent failure, `_stake()` unconditionally proceeds to increment `stakerCountInTree++` and leaves `users[userAddr].outOfTree` as `false` (its default). This creates a desynchronization: `stakerCountInTree` is inflated, and the user's status flag `outOfTree` is inconsistent with their actual absence from the Fenwick tree.

### Internal Pre-conditions

1. `LayerEdgeStaking.nextJoinId` needs to be `MAX_USERS + 1` i.e. `100_000_001` unique joinIds have already been notionally assigned.


### External Pre-conditions

Natural usage or an attacker can accelerate reaching the internal pre-condition by performing many stake/unstake cycles with unique wallets.

### Vulnerability Path

1. The protocol operates, and through normal usage or accelerated by an attacker, `nextJoinId` becomes `MAX_USERS + 1` i.e `100_000_001`
2. A new user `Bob` calls `stake()` with `amount >= minStakeAmount`.
3. `Bob` is assigned `joinId` = `100_000_001`.
4. `stakerTree.update(Bob.joinId, 1)` is called. As `Bob.joinId > stakerTree.size`, the Fenwick Tree does not register this user:

```solidity
function update(Tree storage self, uint256 index, int256 delta) internal {
        require(index > 0, "Index must be > 0");
        while (index <= self.size) {
            self.data[index] = uint256(int256(self.data[index]) + delta);
            index += lsb(index);
        }
    }
```
The call does not revert.

5. The `_stake()` function continues and increments `stakerCountInTree`.
6. `users[Bob].outOfTree` remains false.
7. The transaction succeeds, leaving the contract with broken inflated state:
- To put it in clear numbers the fenwicktree might have `1_000_000` active users in its system due to some having unstaked etc.
- When the system calls `_checkBoundariesAndRecord(false)` the bug will make it seem as though there are `1_000_001` active users in the `fenwicktree` meanwhile there are not, due to the incorrectly inflated `stakerCountInTree` value that would be the one that has `1_000_001`. So for clarity the amount of users in the `fenwicktree` should always match the `stakerCountInTree` state, otherwise this invariant is broken:

> Tier distribution correctness: Exactly 20% in Tier 1, 30% in Tier 2, and 50% in Tier 3 (with minimum guarantees of at least 1 user per tier when applicable)

As there would be "phantom" users present in the `fenwicktree` that are not really there.

### Impact

1. Incorrect State Accounting: `stakerCountInTree` becomes inflated and no longer accurately represents the actual number of users present in the Fenwick tree.
2. Flawed Tier Calculations: All subsequent tier boundary calculations performed by `getTierCountForStakerCount()` use this inflated `stakerCountInTree`. This means the percentage based slots for Tier 1, Tier 2, and the rank based Tier 3 are determined based on an incorrect total. This can lead to an incorrect number of slots being allocated to higher tiers than warranted by the actual number of ranked participants, or incorrect demotions/promotions when `_checkBoundariesAndRecord` runs.
3. Incorrect Tier the user: `Bob` (who received the `joinId > MAX_USERS`) will get `rank = 0` from `stakerTree.query()`, resulting in them being assigned `Tier.Tier3`. While this is a "safe" tier, their entry contributed to the incorrect `stakerCountInTree` used for others.
4. Broken Tier System: The fundamental promise of a 20/30/50 split based on actual ranked participants is broken because the denominator (`stakerCountInTree`) is incorrect or does not reflect reality. This affects the perceived fairness and APY expectations for all `inTree` users.

Overral, since there is a cap of `100_000_000` **ACTIVE** wallets within the `fenwicktree` branch, in theory it should be capped there, but because this bug inflates the `stakerCountInTree` variable, the contract will handle the tier system as though there are more wallets than the `MAX_USERS` should allow present in the tree which in reality would not be the case, which breaks a key invariant and can lead to unwarranted promotions in the tier system, effectively stealing yield from honest stakers.

### PoC

See Vulnerability Path

### Mitigation

In LayerEdgeStaking.sol::_stake, before assigning a joinId and attempting to add a user to the competitive tier system, add a check:

```solidity
if (!user.isActive && amount >= minStakeAmount) {
    require(nextJoinId <= MAX_USERS, "LayerEdgeStaking: Maximum tiered staker capacity reached");
    user.joinId = nextJoinId++;
    // ... rest of the logic ...
}
```

This will cause the transaction to revert if the `MAX_USERS` cap for new `joinIds` is about to be breached, preventing the state desynchronization. Alternatively, if a user stakes when `nextJoinId > MAX_USERS`, they should be treated similarly to users staking less than `minStakeAmount` i.e. directly made `outOfTree = true` and `stakerCountOutOfTree` incremented, without affecting `stakerCountInTree` or the Fenwick tree).